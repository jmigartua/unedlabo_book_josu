
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>10 Non-linear least squares. Least absolute deviation. Principal component analysis &#8212; Applying Maths in the Chemical &amp; Biomolecular Sciences</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-13/analysis-D';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Solutions Q1 -11" href="analysis-answers1-11.html" />
    <link rel="prev" title="Questions 10 - 13" href="analysis-Q10-11.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/book-cover.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/book-cover.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Applying Maths in the Chemical and Biomolecular Sciences.
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="analysis-intro.html">13. Data Analysis</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="analysis-A.html">1 Characterizing experimental data. Accuracy, precision, mean and standard deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="20240510_representacion_datos.html">Datos Pr√°ctica Electricidad I,</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis-Q1-3.html">Questions 1 - 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis-B.html">6 Modelling data. Least squares, chi squared, residuals, ANNOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis-Q4-9.html">Questions 4 - 9</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis-C.html">7 Modelling data is simpler using matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis-Q10-11.html">Questions 10 - 13</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">10 Non-linear least squares. Least absolute deviation. Principal component analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="analysis-answers1-11.html">Solutions Q1 -11</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/subblue/applying-maths-book/main?urlpath=lab/tree/applying_maths_book/chapter-13/analysis-D.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/subblue/applying-maths-book/blob/main/applying_maths_book/chapter-13/analysis-D.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/subblue/applying-maths-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/subblue/applying-maths-book/issues/new?title=Issue%20on%20page%20%2Fchapter-13/analysis-D.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter-13/analysis-D.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>10 Non-linear least squares. Least absolute deviation. Principal component analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-linear-least-squares">10.1 Non-linear  least squares</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#least-absolute-deviation">10.2 Least absolute deviation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-pca">11 Principal component analysis ( PCA )</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="non-linear-least-squares-least-absolute-deviation-principal-component-analysis">
<h1>10 Non-linear least squares. Least absolute deviation. Principal component analysis<a class="headerlink" href="#non-linear-least-squares-least-absolute-deviation-principal-component-analysis" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import all python add-ons etc that will be needed later on </span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">linalg</span> <span class="k">as</span> <span class="n">lina</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span> 
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">scipy.integrate</span> <span class="kn">import</span> <span class="n">quad</span><span class="p">,</span><span class="n">odeint</span>
<span class="n">init_printing</span><span class="p">()</span>                      <span class="c1"># allows printing of SymPy results in typeset maths format</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>  <span class="c1"># set font size for plots</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># import all python add-ons etc that will be needed later on </span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;matplotlib&#39;</span><span class="p">,</span> <span class="s1">&#39;inline&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">linalg</span> <span class="k">as</span> <span class="n">lina</span>

<span class="nn">File ~/anaconda3/envs/jupyterbooks/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2432,</span> in <span class="ni">InteractiveShell.run_line_magic</span><span class="nt">(self, magic_name, line, _stack_depth)</span>
<span class="g g-Whitespace">   </span><span class="mi">2430</span>     <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;local_ns&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_local_scope</span><span class="p">(</span><span class="n">stack_depth</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2431</span> <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">builtin_trap</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">2432</span>     <span class="n">result</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2434</span> <span class="c1"># The code below prevents the output from being displayed</span>
<span class="g g-Whitespace">   </span><span class="mi">2435</span> <span class="c1"># when using magics with decorator @output_can_be_silenced</span>
<span class="g g-Whitespace">   </span><span class="mi">2436</span> <span class="c1"># when the last Python token in the expression is a &#39;;&#39;.</span>
<span class="g g-Whitespace">   </span><span class="mi">2437</span> <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">magic</span><span class="o">.</span><span class="n">MAGIC_OUTPUT_CAN_BE_SILENCED</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>

<span class="nn">File ~/anaconda3/envs/jupyterbooks/lib/python3.11/site-packages/IPython/core/magics/pylab.py:99,</span> in <span class="ni">PylabMagics.matplotlib</span><span class="nt">(self, line)</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span>     <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Available matplotlib backends: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">backends_list</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">98</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">99</span>     <span class="n">gui</span><span class="p">,</span> <span class="n">backend</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shell</span><span class="o">.</span><span class="n">enable_matplotlib</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gui</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gui</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">gui</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">100</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_show_matplotlib_backend</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gui</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbooks/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3606,</span> in <span class="ni">InteractiveShell.enable_matplotlib</span><span class="nt">(self, gui)</span>
<span class="g g-Whitespace">   </span><span class="mi">3585</span> <span class="k">def</span> <span class="nf">enable_matplotlib</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gui</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">3586</span><span class="w">     </span><span class="sd">&quot;&quot;&quot;Enable interactive matplotlib and inline figure support.</span>
<span class="g g-Whitespace">   </span><span class="mi">3587</span><span class="sd"> </span>
<span class="g g-Whitespace">   </span><span class="mi">3588</span><span class="sd">     This takes the following steps:</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">   </span><span class="mi">3604</span><span class="sd">         display figures inline.</span>
<span class="g g-Whitespace">   </span><span class="mi">3605</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">-&gt; </span><span class="mi">3606</span>     <span class="kn">from</span> <span class="nn">matplotlib_inline.backend_inline</span> <span class="kn">import</span> <span class="n">configure_inline_support</span>
<span class="g g-Whitespace">   </span><span class="mi">3608</span>     <span class="kn">from</span> <span class="nn">IPython.core</span> <span class="kn">import</span> <span class="n">pylabtools</span> <span class="k">as</span> <span class="n">pt</span>
<span class="g g-Whitespace">   </span><span class="mi">3609</span>     <span class="n">gui</span><span class="p">,</span> <span class="n">backend</span> <span class="o">=</span> <span class="n">pt</span><span class="o">.</span><span class="n">find_gui_and_backend</span><span class="p">(</span><span class="n">gui</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pylab_gui_select</span><span class="p">)</span>

<span class="n">File</span> <span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">jupyterbooks</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.11</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">matplotlib_inline</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">backend_inline</span><span class="p">,</span> <span class="n">config</span>  <span class="c1"># noqa</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;0.1.6&quot;</span>  <span class="c1"># noqa</span>

<span class="n">File</span> <span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">jupyterbooks</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.11</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">matplotlib_inline</span><span class="o">/</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">6</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span><span class="w"> </span><span class="sd">&quot;&quot;&quot;A matplotlib backend for publishing figures via display_data&quot;&quot;&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># Copyright (c) IPython Development Team.</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># Distributed under the terms of the BSD 3-Clause License.</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">colors</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="kn">from</span> <span class="nn">matplotlib.backends</span> <span class="kn">import</span> <span class="n">backend_agg</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;matplotlib&#39;
</pre></div>
</div>
</div>
</div>
<section id="non-linear-least-squares">
<h2>10.1 Non-linear  least squares<a class="headerlink" href="#non-linear-least-squares" title="Permalink to this heading">#</a></h2>
<p>In the least squares method, the derivative of the <span class="math notranslate nohighlight">\(\chi^2\)</span> is taken with respect to each parameter <span class="math notranslate nohighlight">\(\alpha_i\)</span> and minimized. The normal equations of linear least squares analysis (equations 28,44), have terms only in <span class="math notranslate nohighlight">\(a_ix\)</span> or <span class="math notranslate nohighlight">\(a_ix^2\)</span> etc., and can be solved exactly. In non-linear least squares, the normal equations cannot be solved exactly. The function</p>
<div class="math notranslate nohighlight">
\[Y = \alpha_1e^{-\alpha_2x} + \alpha_3e^{-\alpha_4x} + \alpha_5\]</div>
<p>has a form that is common to several schemes in chemical kinetics and when analysing the decay of excited states, but in this function the normal equations still contain exponentials in <span class="math notranslate nohighlight">\(\alpha_i\)</span> and <span class="math notranslate nohighlight">\(x\)</span>, for example <span class="math notranslate nohighlight">\(e^{-\alpha_2x}\)</span> and cannot be solved exactly. An approximate numerical solution has to be sought, usually by an iterative method. Any iterative method follows an algorithm that tries to approach the minimum <span class="math notranslate nohighlight">\(\chi^2\)</span> without searching through the whole range of possible values of the parameters (<span class="math notranslate nohighlight">\(\alpha\)</span>‚Äôs). There are several algorithms to choose from, some, such as the simplex, simulated annealing (Prest et al. 1986), and evolutionary (natural selection) algorithms are not least squares methods; however, the best algorithm for non-linear least squares is the Levenberg - Marquardt algorithm (Bevington 1969; Prest et al. 1986; Bevington &amp; Robinson 2003). Importantly, it is easy to implement and operates stably, i.e. it hardly ever fails.</p>
<p>Using a numerical method implies</p>
<p><strong>(i)</strong><span class="math notranslate nohighlight">\(\quad\)</span> that starting values have to be defined for each of the parameters sought,</p>
<p><strong>(ii)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  increments in these have to be determined and are changed as the calculation proceeds,</p>
<p><strong>(iii)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  some ending condition has been specified for an acceptable fit to the data.</p>
<p>These requirements mean that this problem is far harder to solve than is linear least-squares, partly for the reasons given, but also because there is no guarantee that the true minimum will be found even if the calculation appears to end satisfactorily. This last effect has two forms. The first is that close to the minimum solution several related sets of parameters can satisfy the same goodness of fit criterion, so that a unique set is not found, only a range of them. The second effect is that the ‚Äòsurface‚Äô through and about which the minimum <span class="math notranslate nohighlight">\(\chi^2\)</span> is sought may be rough, with local minima in which the calculation can become trapped.</p>
<p>The <span class="math notranslate nohighlight">\(\chi^2\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[\displaystyle \chi^2=\sum_{i=1}^n w_i(y_i-Y_i(\alpha_j))^2 \]</div>
<p>where the subscript <span class="math notranslate nohighlight">\(i\)</span> identifies the data points and <span class="math notranslate nohighlight">\(j\)</span> the parameters, <span class="math notranslate nohighlight">\(\alpha_1, \alpha_2\cdots\)</span>. The <span class="math notranslate nohighlight">\(\chi^2\)</span> surface would ideally be shaped rather like a bowl so that it can be imagined how starting at one point the minimum can be reached. But it is instead highly complex, and can be represented as a three-dimensional object only if two parameters are used and if there are more, and there usually are, it is almost impossible to have an idea what this object may look like. In the best circumstance, the object is smooth and a minimum is found, but generally, it might be supposed that the objects ‚Äòlandscape‚Äô is ‚Äòcorrugated‚Äô with many local minima separated by ‚Äòhills‚Äô and ‚Äòridges‚Äô. However, not withstanding the complexity of the <span class="math notranslate nohighlight">\(\chi^2\)</span> ‚Äòsurface‚Äô, most equations describing physical and chemical phenomena can be success- fully minimized.</p>
<p>Quite often, finding the true minimum starts with initial guesses for the parameters close to the final ones that the calculation will produce. Often, approximate parameters can be guessed by looking at the data; they do not usually have to be that good for the calculation to converge perhaps within a factor of 5 or 10. Alternatively, the literature can be consulted to find values for similar experiments. If this is not possible, as there may be too many variables to find them all, then ranges must be placed on these and perhaps hundreds of sets of parameters can be guessed at random and those with the smallest <span class="math notranslate nohighlight">\(\chi^2\)</span> chosen as starting points. Once the calculation is run, if the results are not particularly good it may be because (a) the function is sensitive to the starting values; (b) it ended up in a local not the global minimum; (c) the calculation did not run long enough to converge; or, if it did converge, (d) the model did not describe the data. Starting the calculation with different initial conditions will usually help to sort this out.</p>
<p>The Levenberg - Marquardt Method combines two different approaches to finding the minimum <span class="math notranslate nohighlight">\(\chi^2\)</span>; Bevington (1969) and Prest et al. (1986) give detailed derivations and equations. The first approach is a gradient-search method that tries to find the steepest descent from any point towards the minimum of the surface that represents the <span class="math notranslate nohighlight">\(\chi^2\)</span>. This method is good when the calculation is a long way from the minimum, as it allows it to be approached rapidly because the gradient is large. When close to the minimum, this method is poor because the gradient may be almost zero and the calculation will creep along, hardly making any progress.</p>
<p>The gradient in the <span class="math notranslate nohighlight">\(\chi^2\)</span> is calculated as <span class="math notranslate nohighlight">\(\displaystyle \sum_{j=1}^n\frac{\partial \chi^2}{\partial \alpha_j}\)</span>. The second aspect to the method is to change the equations close to the minimum where the model function <span class="math notranslate nohighlight">\(Y\)</span> can be accurately expanded as a Taylor series in the parameters <span class="math notranslate nohighlight">\(\alpha_i\)</span> and the <span class="math notranslate nohighlight">\(\chi^2\)</span> is minimized, and normal equations calculated. It turns out, fortunately, that the two sets of equations, steepest descent and expansion, can be changed into one another by varying only one parameter conventionally called <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p>It has been shown that the normal equations 44 can be written in matrix form (equation 48)</p>
<div class="math notranslate nohighlight">
\[\displaystyle \boldsymbol C=\boldsymbol{BA}^{-1}\]</div>
<p>In the linear case, these equations can be solved by inverting matrix <span class="math notranslate nohighlight">\(A\)</span> and left multiplying by matrix <span class="math notranslate nohighlight">\(B\)</span> as is done in Algorithm 3. The equations in the non-linear case are formally the same as those of equation 48 but now the solution must be obtained iteratively. The iterative part has nothing to do with the Marquardt method; this method changes only the diagonals of matrix <span class="math notranslate nohighlight">\(A\)</span> and so moves from a gradient search to a linear expansion of the function. Matrix <span class="math notranslate nohighlight">\(A\)</span> is changed so that</p>
<div class="math notranslate nohighlight">
\[\displaystyle A_{jj}\to A_{jj}(1+\lambda)\]</div>
<p>and <span class="math notranslate nohighlight">\(\lambda\)</span> is changed in the algorithm to go between gradient expansion where <span class="math notranslate nohighlight">\(\lambda\)</span> large, to function linearization where <span class="math notranslate nohighlight">\(\lambda\)</span> is small.</p>
<p>The algorithm (Bevington (1969, Curfit p. 237) and Bevington &amp; Robinson (2003)) is</p>
<p><strong>(i)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  calculate <span class="math notranslate nohighlight">\(\chi^2(\alpha)\)</span></p>
<p><strong>(ii)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  set <span class="math notranslate nohighlight">\(\lambda = 0.001\)</span></p>
<p><strong>(iii)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  calculate <span class="math notranslate nohighlight">\(\chi^2(\alpha +\delta\alpha)\)</span> where <span class="math notranslate nohighlight">\(\delta\alpha\)</span> are the increments in parameters <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p><strong>(iv)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  if <span class="math notranslate nohighlight">\(\chi^2(\alpha+\delta\alpha)&gt;\chi^2(\alpha)\)</span> then <span class="math notranslate nohighlight">\(\lambda\to 10\lambda\)</span> and go to (iii)</p>
<p><strong>(v)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  if <span class="math notranslate nohighlight">\(\chi^2(\alpha+\delta\alpha)&lt;\chi^2(\alpha)\)</span> then <span class="math notranslate nohighlight">\(\lambda \to \lambda/10\)</span>, make <span class="math notranslate nohighlight">\(\alpha \to \alpha+\delta\alpha\)</span> and go to (iii).</p>
<p><strong>(vi)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  check at (iii) whether a preset minimum difference in consecutive <span class="math notranslate nohighlight">\(\chi^2\)</span> is produced or maximum number of iterations reached.</p>
<p>The algorithm is shown below fitted to Poisson distributed data. The data represents a single exponential decay with a constant background and the model function used is <span class="math notranslate nohighlight">\(\displaystyle Y = c_1e^{-c_2x} + c_3\)</span>. The data was simulated, as described in chapter 12.3.4, and the data is</p>
<div class="math notranslate nohighlight">
\[\begin{split}\displaystyle \begin{array}\\
\hline
x &amp;1    &amp; 5    &amp;9   &amp;13  &amp;17  &amp; 21 &amp;25  &amp;29 &amp; 33 &amp;37 &amp;41 &amp;45 &amp;49\\
y &amp;1927 &amp; 1329 &amp;812 &amp;568 &amp;390 &amp;290 &amp;171 &amp;112&amp; 87 &amp;48 &amp;43 &amp;26 &amp;26\\
\hline\\
\hline
x &amp;53   &amp; 57   &amp;61  &amp;65  &amp;69  &amp;73  &amp;77  &amp;81 &amp; 85 &amp;89 &amp;93 &amp;97\\
y &amp;14   &amp; 13   &amp;10  &amp;6   &amp;9   &amp;8   &amp;7   &amp;3  &amp; 9  &amp;5  &amp;4  &amp;8\\
\hline \end{array}\end{split}\]</div>
<p>The true values used to produce the data are <span class="math notranslate nohighlight">\(c_2 = 0.1, c_3 = 5\)</span>, but the initial value of <span class="math notranslate nohighlight">\(c_1\)</span> is unknown as the data has been simulated with <span class="math notranslate nohighlight">\(20000\)</span> events and Poisson distributed noise has been added with a mean value of <span class="math notranslate nohighlight">\(5\)</span>. The total number of counts in the data is <span class="math notranslate nohighlight">\(5925\)</span>, which is rather a small number for an experiment, although single molecule fluorescence measured through a confocal microscope may have far fewer than this. The implementation is based on Bevington (1969, algorithm Curfit).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Algorithm. Levenburg - Marquardt non-linear least squares.</span>

<span class="k">def</span> <span class="nf">chisqrd</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">yval</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">xval</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">C</span><span class="p">)</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">s</span>
<span class="c1">#------------------------------</span>

<span class="k">def</span> <span class="nf">getdata</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">xv</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">yv</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">wv</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>               <span class="c1"># length not known so read in all data and make list of each</span>
        <span class="n">i</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">new_str</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">new_str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
            <span class="n">xv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> 
            <span class="n">yv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> 
            <span class="n">wv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> 
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xv</span><span class="p">)</span>                             <span class="c1"># we do not know length of data before hand </span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">xval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">yval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">wv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>               <span class="c1"># counting weighting</span>
        <span class="n">xval</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">xv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">yval</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">yv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">xval</span><span class="p">,</span><span class="n">yval</span><span class="p">,</span><span class="n">w</span>
<span class="c1">#--------------------------------     </span>

<span class="c1"># fitting model   y = c1.exp(-c2.x) + c3</span>

<span class="n">filename</span><span class="o">=</span><span class="s1">&#39;exponential-data.txt&#39;</span>  <span class="c1"># in rows x , y weighting, </span>
<span class="c1"># data is at end of book in &#39;Appendix, some basic Python instructions&#39;</span>

<span class="n">xval</span><span class="p">,</span><span class="n">yval</span><span class="p">,</span><span class="n">w</span> <span class="o">=</span> <span class="n">getdata</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xval</span><span class="p">)</span>
<span class="n">lambd</span><span class="o">=</span> <span class="mf">0.001</span>            <span class="c1"># initial value</span>
<span class="n">reps</span> <span class="o">=</span> <span class="mi">40</span>               <span class="c1"># typoical value can be altered </span>
<span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">yval</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.55</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># initial guessed values</span>
<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">C</span><span class="p">:</span> <span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span><span class="n">C</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="p">)</span> <span class="o">+</span> <span class="n">C</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># function to be fitted </span>

<span class="n">nf</span>   <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">m</span> <span class="o">-</span> <span class="mi">1</span>                                   <span class="c1"># degrees of freedom</span>
<span class="n">chiB</span> <span class="o">=</span> <span class="mf">1e20</span>                                        <span class="c1"># choose initial value to be huge</span>

<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">deriv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="n">n</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
    <span class="n">beta</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">AA</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">deriv</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">C</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">xval</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>               <span class="c1"># dy/dC[0]</span>
        <span class="n">deriv</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">xval</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">C</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">xval</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="c1"># dy/dC[1]</span>
        <span class="n">deriv</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>                                 <span class="c1"># dy/dC[2]</span>
        <span class="k">pass</span>
    <span class="n">chiA</span> <span class="o">=</span> <span class="n">chisqrd</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">nf</span>
    
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">yval</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">xval</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">C</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="n">deriv</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span>
        <span class="n">beta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">j</span><span class="p">):</span>
            <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">deriv</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">deriv</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> 
            <span class="n">AA</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
        <span class="k">pass</span>
    
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">chiA</span> <span class="o">-</span> <span class="n">chiB</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">0.001</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">AA</span> <span class="o">=</span> <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">AA</span><span class="p">)</span> <span class="o">+</span> <span class="n">AA</span> <span class="p">)</span><span class="o">/</span><span class="mf">2.0</span>                   <span class="c1"># symmetrise</span>
    <span class="k">while</span> <span class="n">chiB</span> <span class="o">&gt;</span> <span class="n">chiA</span><span class="p">:</span>                                   <span class="c1"># step iii</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
                <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">AA</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">AA</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">AA</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">lambd</span>
            <span class="k">pass</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">*</span><span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">ii</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">AA</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">AA</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="n">ii</span><span class="p">]</span> <span class="p">)</span>    
            <span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">+</span> <span class="n">s</span>
            <span class="k">pass</span>
        <span class="n">chiB</span> <span class="o">=</span> <span class="n">chisqrd</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">nf</span>                                
        <span class="n">lambd</span> <span class="o">=</span> <span class="n">lambd</span><span class="o">*</span><span class="mi">10</span>          <span class="c1"># step iv</span>
        <span class="k">pass</span>                      <span class="c1"># end while step iii  ChiB &gt; chiA</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">B</span>                         <span class="c1"># replace coeffs</span>
    <span class="n">chiB</span>  <span class="o">=</span> <span class="n">chiA</span>                  <span class="c1"># replace chi^2</span>
    <span class="n">lambd</span> <span class="o">=</span> <span class="n">lambd</span><span class="o">/</span><span class="mi">10</span>              <span class="c1"># step iv</span>
    <span class="k">pass</span>                          <span class="c1"># end loop on L </span>
    
<span class="n">sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span> <span class="n">m</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">sig</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">/</span><span class="p">(</span> <span class="n">AA</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:s}{:d}{:s}{:8.4g}{:s}{:6.2g}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39; = &#39;</span><span class="p">,</span> <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39; +/- &#39;</span><span class="p">,</span><span class="n">sig</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:s}{:6.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;reduced chi sqrd = &#39;</span><span class="p">,</span><span class="n">chiA</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:s}{:8.4g}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;total calculated counts   =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xval</span><span class="p">[:],</span><span class="n">C</span><span class="p">[:])))</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:s}{:8.4g}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;total experimental counts =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">yval</span><span class="p">[:]</span> <span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C1 =     2128 +/-     30
C2 =   0.1011 +/- 0.0011
C3 =    5.045 +/-   0.72
reduced chi sqrd =  0.883
total calculated counts   =    5910
total experimental counts =    5925
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fchi</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">gamma</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span> <span class="c1"># chi sqrd function</span>
<span class="n">Q</span><span class="p">,</span><span class="n">err</span> <span class="o">=</span> <span class="n">quad</span><span class="p">(</span><span class="n">fchi</span> <span class="p">,</span> <span class="n">chiA</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="p">)</span>    <span class="c1"># integrate from chisqrd to infinity</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:s}</span><span class="s1"> </span><span class="si">{:6.3f}</span><span class="s1"> </span><span class="si">{:s}</span><span class="s1"> </span><span class="si">{:6.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;probability of getting chi-sqrd &gt; &#39;</span><span class="p">,</span><span class="n">chiA</span><span class="o">*</span><span class="n">n</span><span class="p">,</span><span class="s1">&#39; is&#39;</span><span class="p">,</span> <span class="n">Q</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>probability of getting chi-sqrd &gt;  22.066  is  0.632
</pre></div>
</div>
</div>
</div>
<p><img alt="Drawing" src="../_images/analysis-fig14.png" /></p>
<p>Figure 14. Non-linear least squares fit to  <span class="math notranslate nohighlight">\(\displaystyle Y = c_1e^{-c_2x} + c_3\)</span> with <span class="math notranslate nohighlight">\(c_1= 2128, c_2 = 0.1\)</span>, and <span class="math notranslate nohighlight">\(c_3 = 5.05\)</span>.</p>
<p>The calculation produces a <span class="math notranslate nohighlight">\(\chi^2= 0.9\)</span> and that corresponds to a probability of <span class="math notranslate nohighlight">\(63\)</span>% which is near perfect; a perfect value of <span class="math notranslate nohighlight">\(1\)</span> produces a <span class="math notranslate nohighlight">\(50\)</span>% chance. The model curve clearly fits the data as shown in Figure 14. The total counts predicted by the model are almost the same as in the data itself, also indicating a close fit. The normalized residuals are calculated as <span class="math notranslate nohighlight">\((y_i - Y_i)/y_i\)</span>.</p>
</section>
<section id="least-absolute-deviation">
<h2>10.2 Least absolute deviation<a class="headerlink" href="#least-absolute-deviation" title="Permalink to this heading">#</a></h2>
<p>Any least squares method is very sensitive to outliers in the data; see figure 15. You can ‚Äòeyeball‚Äô data and see roughly where a straight line should go through the majority of the data points; however, the least squares line will generally not follow this trend because it is pulled off by the outliers. In such cases, the function to minimize is the absolute value of the deviation rather than the <span class="math notranslate nohighlight">\(\chi^2\)</span> and for an unweighted straight-line fit is the sum</p>
<div class="math notranslate nohighlight">
\[\displaystyle \sum_i |y_i-a-bx_i|\]</div>
<p>Using this function now produces a far better fit to the data, but there is no <span class="math notranslate nohighlight">\(\chi^2\)</span> with which to estimate how good this fit is. Taking the absolute value of the distance from the best fit line, rather than the square of the distance, means that the effect of large deviations is reduced. Prest et al. (1986) give an algorithm with which to calculate the minimum deviation line and this is shown in figure 15.</p>
<p><img alt="Drawing" src="../_images/analysis-fig15.png" /></p>
<p>Figure 15. Outliers produce a least squares fit that does not reflect the trend exhibited by most of the data points. The line passing mainly through the data is the least absolute deviation LAD line.</p>
</section>
<hr class="docutils" />
<section id="principal-component-analysis-pca">
<h2>11 Principal component analysis ( PCA )<a class="headerlink" href="#principal-component-analysis-pca" title="Permalink to this heading">#</a></h2>
<p>In the life sciences, the experimental techniques of chemical physics, for instance, NMR, FTIR, mass spectrometry, and various chromatographic methods are widely used and they produce large quantities of data. The data may consist of hundreds of data sets each containing data from thousands of proteins and metabolites and from which the presence of a few target molecules may be sought. For example, NMR spectra taken on blood plasma will contain signals from thousands of compounds. If samples are taken from a group of patients with a particular disease and a similar group without the disease, the two sets of NMRs can be compared in an attempt to identify markers that may be used to target the disease, either in an attempt either to cure it, or act as an assay to identify its early stages. However, these spectra will be different due to normal variability, will be highly congested and contain numerous overlapping signals from proteins, lipids, sugars, and DNA not involved in the disease. The task is to find the species that are either present or are missing in the diseased group. The problem is that there is an abundance of data but no results.</p>
<p>Data from any instrument is not always in the form that most easily allows the results required to be extracted from it. PCA attempts to rotate the axes with which the data is presented in such a way as to isolate each of its features independently of all of the others. This method produces new variables that are linear combinations of the original data and these are the principal components; mathematically a new orthogonal basis set is produced with which to represent the data (Jolliffe 2002; Miller &amp; Miller 2005). Recall that in changing a basis, the data (a vector) is unaffected only the axes are changed. Some of these new components may contain only background or noise while others contain the data. Sorting out which ones to keep requires some judgement; the process is not automatic. The PCA method is therefore a way of reducing the size of a data set, the penalty is that some data is lost; however, this may not be significant, simply necessary to expose the pertinent data. This type of analysis is therefore always a balance between simplifying the problem to make it understandable and loosing information. Note that principal component analysis is a non-parametric method of analysing data; correlations are sought between data sets without using any model to describe the data. In contrast, the least squares method is a <em>parametric</em> method because a model (equation) is used to test the data.</p>
<p>A set of data can be represented as an expansion of coefficients <span class="math notranslate nohighlight">\(a\)</span> in a basis set <span class="math notranslate nohighlight">\(w\)</span> of length, or dimension, <span class="math notranslate nohighlight">\(n\)</span>,</p>
<div class="math notranslate nohighlight">
\[\displaystyle x=a_1w_1+a_2w_2+\cdots +a_nw_n\]</div>
<p>The same data can also be expressed in another basis set <span class="math notranslate nohighlight">\(u\)</span> as</p>
<div class="math notranslate nohighlight">
\[\displaystyle x=b_1u_1 +b_2u_2 +\cdots + b_nu_n\]</div>
<p>but with a different set of coefficients, <span class="math notranslate nohighlight">\(b\)</span>. This distinction is illustrated in figure 16 where any data point has approximately equal values of coefficients <span class="math notranslate nohighlight">\(a\)</span>, because it is approximately equally positioned between the three experimental x-axes whereas those on the new axes <span class="math notranslate nohighlight">\(p\)</span>, have a large initial value <span class="math notranslate nohighlight">\(b_1\)</span>, along <span class="math notranslate nohighlight">\(p_1\)</span> and smaller ones along <span class="math notranslate nohighlight">\(p_2\)</span> and <span class="math notranslate nohighlight">\(p_3\)</span>.</p>
<p>PCA changes the basis set to optimize the variance placing the principal axis along the direction of maximum spread or variance of the data, and other principal components orthogonally to this. Figure 16 also shows the new axes <span class="math notranslate nohighlight">\(p\)</span> as the principal component axes, two of which are shown on the right and where two regions of data are identified. The missing data in this graph compared to the one on the left is in the direction <span class="math notranslate nohighlight">\(p_3\)</span> and not <span class="math notranslate nohighlight">\(p_2\)</span>, and would be seen on a plot of <span class="math notranslate nohighlight">\(p_1\)</span> vs <span class="math notranslate nohighlight">\(p_3\)</span> and in this way, the change of axes (basis set) can identify different groups of data. The next step in PCA is to reduce the size of the basis set used; this means describing the data in the basis set <span class="math notranslate nohighlight">\(u\)</span> with a smaller set of terms in the summation; <span class="math notranslate nohighlight">\(s\)</span> instead of <span class="math notranslate nohighlight">\(n\)</span>. Because the change of axes puts more contributions of each data point along each principal axis, fewer terms are now needed to form an acceptable description of the data, although all the basis set is needed to reproduce the data exactly. A reduced data set is often the rationale for using PCA, with the aim of identifying new signals, removing noise and/or isolating known interfering signals.</p>
<p><img alt="Drawing" src="../_images/analysis-fig16.png" /></p>
<p>Figure 16. Data on the experimental axes (left), and on the axes of principal components (right)</p>
<hr class="docutils" />
<p>Matrix methods are used to find the principal components (PC). The data comprises m sets where each set has n data points. The whole data forms an n √óm matrix, D, with each data point in a new row of a given column and these vectors form m columns. The steps to find the principal components are:</p>
<p><strong>(i)</strong><span class="math notranslate nohighlight">\(\quad\)</span> Remove the mean value from each of the individual datasets so that the centroid of the data becomes the origin of the new axes. In matrix form subtracting the mean from each data point is
$<span class="math notranslate nohighlight">\(\displaystyle \boldsymbol X= \boldsymbol D -\boldsymbol \mu\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol D\)</span> is the <span class="math notranslate nohighlight">\(n\times m\)</span> matrix of data and <span class="math notranslate nohighlight">\(\boldsymbol \mu\)</span> an <span class="math notranslate nohighlight">\(n\times m\)</span> matrix with the appropriate mean value in each element of its columns. The PC.s are also sensitive to the scale of the data, so it may be necessary to divide the data by the variance giving each set a mean of zero and unit standard deviation during the calculation.<br>
<strong>(ii)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  The covariance of the data is then calculated, this is an <span class="math notranslate nohighlight">\(m\times m\)</span> symmetrical matrix</p>
<div class="math notranslate nohighlight">
\[\boldsymbol C=\frac{1}{n-1}\boldsymbol{XX^T}\qquad\tag{52}\]</div>
<p>The superscript <span class="math notranslate nohighlight">\(T\)</span> is the transpose, and the matrix multiplication has dimensions <span class="math notranslate nohighlight">\((m \times n)\cdot(n \times m) = m \times m)\)</span>. (The <span class="math notranslate nohighlight">\(n-1\)</span> makes an unbiased estimate). The entries in this matrix would be diagonal if the data were random, because each value is then independent of every other. However, this is very unlikely to be the case unless the data contains only random noise; therefore, off-diagonal terms are not zero. The covariance describes how much the data is spread among the axes. If the data were to lie only along each axis the covariance would be diagonal, the rotation of axes accompanying the principal components reduces the off-diagonal component in the covariance.</p>
<p><strong>(iii)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  The m eigenvalues <span class="math notranslate nohighlight">\(\lambda\)</span> and (column) eigenvectors <span class="math notranslate nohighlight">\(V\)</span> (<span class="math notranslate nohighlight">\(m\times m\)</span> matrix) of the covariance matrix <span class="math notranslate nohighlight">\(C\)</span> are calculated and the eigenvalues are sorted from largest to smallest and the eigenvectors are placed in the same order see chapter 7.12.3. The eigenvalue-eigenvector equation is <span class="math notranslate nohighlight">\(\boldsymbol{CV} = \boldsymbol{\Lambda V}\)</span> where <span class="math notranslate nohighlight">\(\Lambda\)</span> is the diagonal matrix of the eigenvalues <span class="math notranslate nohighlight">\(\lambda\)</span>, i.e. a vector. It is assumed that the calculation produces eigenvectors that are normalized, if not they should be normalized by dividing each column by its vector length <span class="math notranslate nohighlight">\(\vec V_i\to \vec V_i/\sqrt{\vec V_i\cdot \vec V_i}\)</span> where <span class="math notranslate nohighlight">\(\vec V_i\)</span> is one column vector. The eigenvectors form the new principal component basis set because they are orthogonal one to another.</p>
<p>The eigenvector of the largest eigenvalue forms the principal component of the data, smaller values the other principal components. The largest contains most of the variance or spread of the data and best describes any trend in the data. The smaller eigenvalues do so to lesser extents depending on their size. The largest s eigenvalues are then chosen to approximate the data. The eigenvalues correspond to variances along the principal axes, thus the fractional value of each eigenvalue to the sum of them all is</p>
<div class="math notranslate nohighlight">
\[\displaystyle \lambda_i/ \sum_i^m\lambda_i\]</div>
<p>and this is the fraction that eigenvalue <span class="math notranslate nohighlight">\(i\)</span> contributes to the data. A measure of the error made by approximating the data by s principal components instead of the total number <span class="math notranslate nohighlight">\(m\)</span>, is the residual variance,</p>
<div class="math notranslate nohighlight">
\[\displaystyle \sigma^2=1-\frac{\sum_i^s \lambda_i}{\sum)i^m \lambda_i}\]</div>
<p>For example, if the first two eigenvalues describe <span class="math notranslate nohighlight">\(85\)</span>% of the data, it may be appropriate to ignore all the others. As a rule of thumb, when selecting data to eliminate, eigenvalues less than <span class="math notranslate nohighlight">\(\approx 1\)</span> can be ignored.</p>
<p><strong>(iv)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  To project the data points onto the new axes, the principal components, the dot product of the data <span class="math notranslate nohighlight">\(\boldsymbol X\)</span> is made with each eigenvector <span class="math notranslate nohighlight">\(\boldsymbol V\)</span>,</p>
<div class="math notranslate nohighlight">
\[\displaystyle \boldsymbol Y = \boldsymbol V^T\boldsymbol X^T\qquad\tag{53}\]</div>
<p>The matrix dimensions are <span class="math notranslate nohighlight">\((m \times m)\cdot(m \times n) = (m \times n)\)</span>. Plotting one row vs another, the data in matrix <span class="math notranslate nohighlight">\(Y\)</span> produces the data along the various principal component axes as shown on the right of figure 16. The first column is <span class="math notranslate nohighlight">\(p_1\)</span>, the second, <span class="math notranslate nohighlight">\(p_2\)</span>, etc. Because the eigenvector (modal) matrix <span class="math notranslate nohighlight">\(V\)</span> is square and orthogonal, the relationship <span class="math notranslate nohighlight">\(\boldsymbol V^{-1} = \boldsymbol V^T\)</span> can be used to reform the original data. The transformation steps are to left multiply both sides of the equation with <span class="math notranslate nohighlight">\(\boldsymbol V\)</span> giving</p>
<div class="math notranslate nohighlight">
\[\displaystyle \boldsymbol{VV}^T\boldsymbol X^T = \boldsymbol{VY}\]</div>
<p>Simplifying the left-hand side produces</p>
<div class="math notranslate nohighlight">
\[\displaystyle \boldsymbol{VV}^T\boldsymbol X^T = \boldsymbol{VV}^{-1}\boldsymbol X^T = \boldsymbol X^T = \boldsymbol{VY}\]</div>
<p>and then <span class="math notranslate nohighlight">\(\boldsymbol{VY}\)</span> is transposed again to form <span class="math notranslate nohighlight">\(\boldsymbol X\)</span> or,</p>
<div class="math notranslate nohighlight">
\[\displaystyle \boldsymbol X=(\boldsymbol{VY})^T, \qquad \boldsymbol D = \boldsymbol X + \boldsymbol\mu\qquad\tag{54}\]</div>
<p>and <span class="math notranslate nohighlight">\(\boldsymbol\mu\)</span> restores the mean to the data <span class="math notranslate nohighlight">\(\boldsymbol D\)</span>.</p>
<p><strong>(v)</strong><span class="math notranslate nohighlight">\(\quad\)</span>  When only <span class="math notranslate nohighlight">\(s\)</span> of the eigenvalues and eigenvectors are being used, the <span class="math notranslate nohighlight">\(V\)</span> matrix is reduced by ignoring all but the first <span class="math notranslate nohighlight">\(s\)</span> columns and equation 54 is used to reconstruct the data.</p>
<p>A python PCA algorithm is detailed below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Algorithm Pricipal component analysis </span>

<span class="n">filename</span><span class="o">=</span><span class="s1">&#39;PCA data.txt&#39;</span>                    <span class="c1"># 3 sets of data 10 values each</span>
<span class="c1"># data is at end of book in &#39;Appendix, some basic Python instructions&#39;</span>

<span class="n">xv</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">yv</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">zv</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">ff</span><span class="p">:</span>                 <span class="c1"># length not known so read in all data and make list of each</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">ff</span><span class="p">:</span>
        <span class="n">new_str</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">new_str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="n">xv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> 
        <span class="n">yv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> 
        <span class="n">zv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vals</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> 
<span class="n">ff</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xv</span><span class="p">)</span>                               <span class="c1"># get length of data </span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">3</span>                                     <span class="c1"># 3 axes of data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> 
    <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">xv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>              <span class="c1"># make lists into arrays, data set 0,1,2 with n values each</span>
    <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">yv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">zv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
<span class="c1"># finished reading     </span>

<span class="n">S</span> <span class="o">=</span> <span class="mi">1</span>                                     <span class="c1"># select first S components eigenvals</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span> 
<span class="n">X</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>  
<span class="n">VS</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span> <span class="p">)</span>
<span class="n">Sev</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                         <span class="c1"># calculate mean value</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">]</span>
    <span class="n">means</span><span class="p">[:,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">/</span><span class="n">n</span>  
    <span class="k">pass</span> 
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">means</span>                           <span class="c1"># subtract mean </span>
<span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>            <span class="c1"># make covariance matrix ( @ is matrix multiply)</span>
<span class="p">(</span><span class="n">eigval</span><span class="p">,</span><span class="n">eigvec</span><span class="p">)</span> <span class="o">=</span> <span class="n">lina</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>              <span class="c1"># eigvals, eigvects of covariance. eigvects normalised</span>

<span class="n">indx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">eigval</span><span class="p">)</span>               

<span class="n">Sev</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">eigval</span><span class="p">[</span>  <span class="n">indx</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>              <span class="c1"># reverse indx array to get largest first</span>
<span class="n">VS</span><span class="p">[:,:]</span><span class="o">=</span> <span class="n">eigvec</span><span class="p">[:,</span><span class="n">indx</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eigenvalues and eigenvectors&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">Sev</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">VS</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span> 

<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">S</span><span class="p">))</span>                        <span class="c1"># do PCA here DR is result                      </span>
<span class="n">V</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">VS</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">S</span><span class="p">]</span>                         <span class="c1"># select S sorted eigenvectors</span>

<span class="n">Y</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">V</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>     <span class="c1"># project onto S new axes </span>

<span class="n">DR</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">V</span> <span class="o">@</span> <span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="n">means</span>           <span class="c1"># DR is data on new axes </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>eigenvalues and eigenvectors
1 4.886993943985875 [ 0.28976365  0.9562666  -0.03989011]
2 0.11490529483430316 [ 0.94367801 -0.2784974   0.17863651]
3 0.08368965006871082 [-0.15971484  0.08940578  0.98310619]
</pre></div>
</div>
</div>
</div>
<p><img alt="Drawing" src="../_images/analysis-fig17.png" /></p>
<p>Figure 17. Left: Data plotted with mean values subtracted together with the principal axes. The major principal axis is (1). Right: Data partly reconstructed (also with mean values subtracted for comparison) with the first eigenvector (red) and then the first two eigenvectors combined (light blue).</p>
<hr class="docutils" />
<p>The figure shows the data (centred at zero by subtracting the mean values), and the three principal axes. The first eigenvector, (1) the major axis, is drawn in a red line. The lengths are arbitrary. The eigenvalues are <span class="math notranslate nohighlight">\(4.9, 0.11, 0.084\)</span>. On the right of the figure, two plots are superimposed. The light blue symbols are the data reconstructed from the first two eigenvectors using equations 53 and 54. The original data is flattened onto the plane of the first two principal axes because the third coordinate is ignored. The second set of data (red symbols) is reconstructed using only the first eigenvalue and is a set of points lying along the principal axis at their relative positions when projected from the other axes. If all three eigenvectors are used the original data is reformed exactly.</p>
<p>Related to PCA is the method of singular value decomposition (SVD). Formally, it is a technique in which one matrix is split into three, one of them is diagonal and the other two are row and column orthogonal as are eigenvector modal matrices (Prest et al. 1986). The reason for expanding a matrix in this way is that it can now be inverted even though it is close to being singular, i.e. inverting it would normally produce infinity or a number that approximates this, and normal inversion methods fail. This method could be used to invert the <span class="math notranslate nohighlight">\(A\)</span> matrix in non-linear least squares, in the example given. The interest in SVD is however not primarily to do with the mathematics but in un-ravelling complex information just as in PCA. SVD can be used either directly on raw data, not the covariance as in PCA, or as a mathematical method to perform PCA (Jolliffe 2002).</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter-13"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="analysis-Q10-11.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Questions 10 - 13</p>
      </div>
    </a>
    <a class="right-next"
       href="analysis-answers1-11.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Solutions Q1 -11</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-linear-least-squares">10.1 Non-linear  least squares</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#least-absolute-deviation">10.2 Least absolute deviation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-pca">11 Principal component analysis ( PCA )</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Godfrey Beddard
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      ¬© Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>